{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Data Collection\"\n",
    "format:\n",
    "    html: \n",
    "        code-fold: false\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{{< include instructions.qmd >}} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "{{< include overview.qmd >}} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{{< include methods.qmd >}} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code \n",
    "\n",
    "Provide the source code used for this section of the project here.\n",
    "\n",
    "If you're using a package for code organization, you can import it at this point. However, make sure that the **actual workflow steps**â€”including data processing, analysis, and other key tasksâ€”are conducted and clearly demonstrated on this page. The goal is to show the technical flow of your project, highlighting how the code is executed to achieve your results.\n",
    "\n",
    "Ensure that the code is well-commented to enhance readability and understanding for others who may review or use it. If relevant, link to additional documentation or external references that explain any complex components. This section should give readers a clear view of how the project is implemented from a technical perspective.\n",
    "\n",
    "This page is a technical narrative, NOT just a notebook with a collection of code cells, include in-line Prose, to describe what is going on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example\n",
    "\n",
    "In the following code, we first utilized the requests library to retrieve the HTML content from the Wikipedia page. Afterward, we employed BeautifulSoup to parse the HTML and locate the specific table of interest by using the find function. Once the table was identified, we extracted the relevant data by iterating through its rows, gathering country names and their respective populations. Finally, we used Pandas to store the collected data in a DataFrame, allowing for easy analysis and visualization. The data could also be optionally saved as a CSV file for further use. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 Country     Population\n",
      "0                                  World  8,119,000,000\n",
      "1                                  China  1,409,670,000\n",
      "2                          1,404,910,000          17.3%\n",
      "3                          United States    335,893,238\n",
      "4                              Indonesia    281,603,800\n",
      "..                                   ...            ...\n",
      "235                   Niue (New Zealand)          1,681\n",
      "236                Tokelau (New Zealand)          1,647\n",
      "237                         Vatican City            764\n",
      "238  Cocos (Keeling) Islands (Australia)            593\n",
      "239                Pitcairn Islands (UK)             35\n",
      "\n",
      "[240 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Send a request to Wikipedia page\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_countries_and_dependencies_by_population'\n",
    "response = requests.get(url)\n",
    "\n",
    "# Step 2: Parse the page content using BeautifulSoup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Step 3: Find the table containing the data (usually the first table for such lists)\n",
    "table = soup.find('table', {'class': 'wikitable'})\n",
    "\n",
    "# Step 4: Extract data from the table rows\n",
    "countries = []\n",
    "populations = []\n",
    "\n",
    "# Iterate over the table rows\n",
    "for row in table.find_all('tr')[1:]:  # Skip the header row\n",
    "    cells = row.find_all('td')\n",
    "    if len(cells) > 1:\n",
    "        country = cells[1].text.strip()  # The country name is in the second column\n",
    "        population = cells[2].text.strip()  # The population is in the third column\n",
    "        countries.append(country)\n",
    "        populations.append(population)\n",
    "\n",
    "# Step 5: Create a DataFrame to store the results\n",
    "data = pd.DataFrame({\n",
    "    'Country': countries,\n",
    "    'Population': populations\n",
    "})\n",
    "\n",
    "# Display the scraped data\n",
    "print(data)\n",
    "\n",
    "# Optionally save to CSV\n",
    "data.to_csv('../../data/raw-data/countries_population.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titles</th>\n",
       "      <th>view_counts</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Taylor Swift - Anti-Hero (Official Music Video)</td>\n",
       "      <td>212893513</td>\n",
       "      <td>Anti-Hero by Taylor Swift</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Taylor Swift - Anti-Hero (Official Lyric Video)</td>\n",
       "      <td>34875876</td>\n",
       "      <td>Anti-Hero by Taylor Swift</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Taylor Swift - Anti-Hero (Lyrics)</td>\n",
       "      <td>14266885</td>\n",
       "      <td>Anti-Hero by Taylor Swift</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Taylor Swift - Anti Hero (Lyrics) &amp;quot;It&amp;#39...</td>\n",
       "      <td>5444496</td>\n",
       "      <td>Anti-Hero by Taylor Swift</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Taylor Swift - Anti-Hero</td>\n",
       "      <td>1332074</td>\n",
       "      <td>Anti-Hero by Taylor Swift</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>Lorde - Tennis Court</td>\n",
       "      <td>131679562</td>\n",
       "      <td>Tennis Court by Lorde</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>Lorde - Tennis Court (Flume Remix)</td>\n",
       "      <td>115590517</td>\n",
       "      <td>Tennis Court by Lorde</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>Lorde - Tennis Court (Audio)</td>\n",
       "      <td>2182597</td>\n",
       "      <td>Tennis Court by Lorde</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>Lorde - Tennis Court (Glastonbury 2017)</td>\n",
       "      <td>365081</td>\n",
       "      <td>Tennis Court by Lorde</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>Tennis Court - Lorde (Lyrics) ðŸŽµ</td>\n",
       "      <td>179298</td>\n",
       "      <td>Tennis Court by Lorde</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>115 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                titles  view_counts  \\\n",
       "0      Taylor Swift - Anti-Hero (Official Music Video)    212893513   \n",
       "1      Taylor Swift - Anti-Hero (Official Lyric Video)     34875876   \n",
       "2                    Taylor Swift - Anti-Hero (Lyrics)     14266885   \n",
       "3    Taylor Swift - Anti Hero (Lyrics) &quot;It&#39...      5444496   \n",
       "4                             Taylor Swift - Anti-Hero      1332074   \n",
       "..                                                 ...          ...   \n",
       "110                               Lorde - Tennis Court    131679562   \n",
       "111                 Lorde - Tennis Court (Flume Remix)    115590517   \n",
       "112                       Lorde - Tennis Court (Audio)      2182597   \n",
       "113            Lorde - Tennis Court (Glastonbury 2017)       365081   \n",
       "114                    Tennis Court - Lorde (Lyrics) ðŸŽµ       179298   \n",
       "\n",
       "                         query  \n",
       "0    Anti-Hero by Taylor Swift  \n",
       "1    Anti-Hero by Taylor Swift  \n",
       "2    Anti-Hero by Taylor Swift  \n",
       "3    Anti-Hero by Taylor Swift  \n",
       "4    Anti-Hero by Taylor Swift  \n",
       "..                         ...  \n",
       "110      Tennis Court by Lorde  \n",
       "111      Tennis Court by Lorde  \n",
       "112      Tennis Court by Lorde  \n",
       "113      Tennis Court by Lorde  \n",
       "114      Tennis Court by Lorde  \n",
       "\n",
       "[115 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from googleapiclient.discovery import build\n",
    "import pandas as pd\n",
    "\n",
    "# API Key\n",
    "api_key = \"AIzaSyDtKE-4QZj6EA-rwG7cj5gMJxdt4Fe14Nw\"\n",
    "\n",
    "# Initialize YouTube API client\n",
    "youtube = build('youtube', 'v3', developerKey=api_key)\n",
    "\n",
    "# List to store data\n",
    "all_data = []\n",
    "\n",
    "# Read song data and fetch YouTube statistics\n",
    "with open('song_data.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        # Strip newline characters and spaces\n",
    "        query = line.strip()\n",
    "\n",
    "        # Search request for the query\n",
    "        search_request = youtube.search().list(\n",
    "            part=\"snippet\",\n",
    "            q=query,  # Use the query from the file\n",
    "            maxResults=5,\n",
    "            type=\"video\",\n",
    "            order='relevance'\n",
    "        )\n",
    "        search_response = search_request.execute()\n",
    "\n",
    "        # Get video IDs\n",
    "        video_ids = [item['id']['videoId'] for item in search_response['items']]\n",
    "        if not video_ids:\n",
    "            continue  # Skip if no results\n",
    "\n",
    "        # Fetch video details (statistics)\n",
    "        video_request = youtube.videos().list(\n",
    "            part=\"statistics\",\n",
    "            id=\",\".join(video_ids)\n",
    "        )\n",
    "        video_response = video_request.execute()\n",
    "\n",
    "        # Collect results for the current query\n",
    "        query_data = []\n",
    "        for item, stats in zip(search_response['items'], video_response['items']):\n",
    "            query_data.append({\n",
    "                \"titles\": item['snippet']['title'],\n",
    "                \"view_counts\": int(stats['statistics']['viewCount']),\n",
    "                \"query\": query\n",
    "            })\n",
    "\n",
    "        # Convert query-specific data to a DataFrame and sort by view_counts\n",
    "        query_df = pd.DataFrame(query_data)\n",
    "        query_df = query_df.sort_values(by=\"view_counts\", ascending=False)\n",
    "\n",
    "        # Append the sorted data to the final list\n",
    "        all_data.append(query_df)\n",
    "\n",
    "# Concatenate all sorted query-specific DataFrames into one\n",
    "final_df = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "final_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('view_counts.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{{< include closing.qmd >}} "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
